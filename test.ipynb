{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import WeightedRandomSampler, random_split, DataLoader\n",
    "\n",
    "from lifi.data.Loader import ImageDataset, LabelEnum\n",
    "from lifi.train import get_label_probabilities\n",
    "\n",
    "data_folder = Path(\"./images\")\n",
    "db = ImageDataset(data_folder)\n",
    "train_db, test_db = random_split(db, [0.7, 0.3])\n",
    "label_probas = get_label_probabilities(train_db)\n",
    "sampler = WeightedRandomSampler(label_probas, len(train_db))\n",
    "train_loader = DataLoader(train_db, 32, shuffle=True, num_workers=4)\n",
    "test_loader  = DataLoader(test_db, 32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import RandomApply\n",
    "\n",
    "from lifi.data.Augmentinator import Augmentinator, default_transforms\n",
    "\n",
    "x, y = train_db[0]\n",
    "transform_dict = default_transforms(x.shape)\n",
    "transforms = RandomApply(torch.nn.ModuleList([\n",
    "    t for t in transform_dict.values()\n",
    "]), p=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd42833c5d904c3e925dd66c86a5b4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joep/Code/Leafliction/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2299, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e02bfee59bb4e7ba80716c6a5b78aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lifi.models import BasicClassifier\n",
    "\n",
    "net = BasicClassifier(num_classes=len(LabelEnum))\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "net = net.cuda()\n",
    "optim = Adam(net.parameters())\n",
    "\n",
    "for _ in range(2):\n",
    "    for x, y in tqdm(train_loader):\n",
    "        optim.zero_grad()\n",
    "        x = x.cuda()\n",
    "        x = net.preprocess(x)\n",
    "        x = transforms(x)\n",
    "        y = y.cuda()\n",
    "        y_hat = net(x)\n",
    "        loss = ce_loss(y_hat, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046ff7aa59014bec96dbbf4f3667feec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joep/Code/Leafliction/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preds, gts = [], []\n",
    "\n",
    "for x, y in tqdm(test_loader):\n",
    "    x = x.cuda()\n",
    "    x = net.preprocess(x)\n",
    "    y = y.cuda()\n",
    "    y_hat = torch.argmax(net(x), dim=1)\n",
    "    preds.append(y_hat.cpu())\n",
    "    gts.append(y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds_np = np.array(torch.concat(preds).view(-1))\n",
    "gts_np   = np.array(torch.concat(gts).view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9834254143646409"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds_np == gts_np).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Apple_Black_rot  Apple_healthy  ...    macro avg  weighted avg\n",
      "precision         0.958333        0.98167  ...     0.980459      0.983568\n",
      "recall            0.978723        0.98167  ...     0.981565      0.983425\n",
      "f1-score          0.968421        0.98167  ...     0.980960      0.983452\n",
      "support         188.000000      491.00000  ...  2172.000000   2172.000000\n",
      "\n",
      "[4 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "report = classification_report(gts_np, preds_np, target_names=[LabelEnum(i).name for i in range(len(LabelEnum))], output_dict=True)\n",
    "pd.DataFrame.from_dict(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
