{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import WeightedRandomSampler, random_split, DataLoader\n",
    "\n",
    "from lifi.data.Loader import ImageDataset, LabelEnum\n",
    "from lifi.train import get_label_probabilities\n",
    "\n",
    "data_folder = Path(\"./images\")\n",
    "db = ImageDataset(data_folder)\n",
    "train_db, test_db = random_split(db, [0.7, 0.3])\n",
    "label_probas = get_label_probabilities(train_db)\n",
    "sampler = WeightedRandomSampler(label_probas, len(train_db))\n",
    "train_loader = DataLoader(train_db, 32, shuffle=True, num_workers=4)\n",
    "test_loader  = DataLoader(test_db, 32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import RandomApply\n",
    "\n",
    "from lifi.data.Augmentinator import Augmentinator, default_transforms\n",
    "\n",
    "x, y = train_db[0]\n",
    "transform_dict = default_transforms(x.shape)\n",
    "transforms = RandomApply(torch.nn.ModuleList([\n",
    "    t for t in transform_dict.values()\n",
    "]), p=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd42833c5d904c3e925dd66c86a5b4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joep/Code/Leafliction/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2299, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e02bfee59bb4e7ba80716c6a5b78aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lifi.models import BasicClassifier\n",
    "\n",
    "net = BasicClassifier(num_classes=len(LabelEnum))\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "net = net.cuda()\n",
    "optim = Adam(net.parameters())\n",
    "\n",
    "for _ in range(2):\n",
    "    for x, y in tqdm(train_loader):\n",
    "        optim.zero_grad()\n",
    "        x = x.cuda()\n",
    "        x = net.preprocess(x)\n",
    "        x = transforms(x)\n",
    "        y = y.cuda()\n",
    "        y_hat = net(x)\n",
    "        loss = ce_loss(y_hat, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046ff7aa59014bec96dbbf4f3667feec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joep/Code/Leafliction/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preds, gts = [], []\n",
    "\n",
    "for x, y in tqdm(test_loader):\n",
    "    x = x.cuda()\n",
    "    x = net.preprocess(x)\n",
    "    y = y.cuda()\n",
    "    y_hat = torch.argmax(net(x), dim=1)\n",
    "    preds.append(y_hat.cpu())\n",
    "    gts.append(y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds_np = np.array(torch.concat(preds).view(-1))\n",
    "gts_np   = np.array(torch.concat(gts).view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9834254143646409"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds_np == gts_np).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Apple_Black_rot  Apple_healthy  ...    macro avg  weighted avg\n",
      "precision         0.958333        0.98167  ...     0.980459      0.983568\n",
      "recall            0.978723        0.98167  ...     0.981565      0.983425\n",
      "f1-score          0.968421        0.98167  ...     0.980960      0.983452\n",
      "support         188.000000      491.00000  ...  2172.000000   2172.000000\n",
      "\n",
      "[4 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "report = classification_report(gts_np, preds_np, target_names=[LabelEnum(i).name for i in range(len(LabelEnum))], output_dict=True)\n",
    "pd.DataFrame.from_dict(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from lifi.models import BasicClassifier\n",
    "from lifi.data.labels import LabelEnum\n",
    "\n",
    "net = BasicClassifier()\n",
    "state_dict = torch.load('leaf_classifier.pt', map_location='cpu')\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grape_Esca\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "totens = ToTensor()\n",
    "paf = \"./correction/fix/Apple_Black_rot/Apple_Black_rot1.jpg\"\n",
    "im = totens(Image.open(paf))\n",
    "\n",
    "pred = torch.softmax(net(net.preprocess(im.unsqueeze(0))), dim=1)[0]\n",
    "{LabelEnum(i).name: p.item() for i, p in enumerate(pred)}\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "x = im.to(device).unsqueeze(0)\n",
    "x = net.preprocess(x)\n",
    "y_hat = torch.argmax(torch.softmax(net(x), dim=1), dim=1)\n",
    "print(LabelEnum(y_hat.item()).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised ImageDataset on folder correction/fix with 10 images.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from lifi.data.Loader import ImageDataset\n",
    "from lifi.train import eval_model\n",
    "\n",
    "data_folder = Path(\"./correction/fix/\")\n",
    "test_db = ImageDataset(data_folder)\n",
    "test_loader = DataLoader(test_db, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model:   0%|          | 0/10 [00:00<?, ?it/s]/home/joep/Code/Leafliction/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "Evaluating model: 100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple_Black_rot</th>\n",
       "      <th>Apple_healthy</th>\n",
       "      <th>Apple_rust</th>\n",
       "      <th>Apple_scab</th>\n",
       "      <th>Grape_Black_rot</th>\n",
       "      <th>Grape_Esca</th>\n",
       "      <th>Grape_healthy</th>\n",
       "      <th>Grape_spot</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Apple_Black_rot  Apple_healthy  Apple_rust  Apple_scab  \\\n",
       "precision              1.0            1.0         1.0         1.0   \n",
       "recall                 1.0            1.0         1.0         1.0   \n",
       "f1-score               1.0            1.0         1.0         1.0   \n",
       "support                1.0            2.0         1.0         1.0   \n",
       "\n",
       "           Grape_Black_rot  Grape_Esca  Grape_healthy  Grape_spot  accuracy  \\\n",
       "precision              1.0         1.0            1.0         1.0       1.0   \n",
       "recall                 1.0         1.0            1.0         1.0       1.0   \n",
       "f1-score               1.0         1.0            1.0         1.0       1.0   \n",
       "support                2.0         1.0            1.0         1.0       1.0   \n",
       "\n",
       "           macro avg  weighted avg  \n",
       "precision        1.0           1.0  \n",
       "recall           1.0           1.0  \n",
       "f1-score         1.0           1.0  \n",
       "support         10.0          10.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(test_loader, net, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85e9db4d2bd4823a740efa0183a060e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating model:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  Apple_scab Apple_scab\n",
      "pred:  Apple_rust Apple_rust\n",
      "pred:  Apple_healthy Apple_healthy\n",
      "pred:  Apple_healthy Apple_healthy\n",
      "pred:  Grape_spot Grape_spot\n",
      "pred:  Grape_Black_rot Grape_Black_rot\n",
      "pred:  Grape_Black_rot Grape_Black_rot\n",
      "pred:  Apple_Black_rot Apple_Black_rot\n",
      "pred:  Grape_healthy Grape_healthy\n",
      "pred:  Grape_Esca Grape_Esca\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple_Black_rot</th>\n",
       "      <th>Apple_healthy</th>\n",
       "      <th>Apple_rust</th>\n",
       "      <th>Apple_scab</th>\n",
       "      <th>Grape_Black_rot</th>\n",
       "      <th>Grape_Esca</th>\n",
       "      <th>Grape_healthy</th>\n",
       "      <th>Grape_spot</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Apple_Black_rot  Apple_healthy  Apple_rust  Apple_scab  \\\n",
       "precision              1.0            1.0         1.0         1.0   \n",
       "recall                 1.0            1.0         1.0         1.0   \n",
       "f1-score               1.0            1.0         1.0         1.0   \n",
       "support                1.0            2.0         1.0         1.0   \n",
       "\n",
       "           Grape_Black_rot  Grape_Esca  Grape_healthy  Grape_spot  accuracy  \\\n",
       "precision              1.0         1.0            1.0         1.0       1.0   \n",
       "recall                 1.0         1.0            1.0         1.0       1.0   \n",
       "f1-score               1.0         1.0            1.0         1.0       1.0   \n",
       "support                2.0         1.0            1.0         1.0       1.0   \n",
       "\n",
       "           macro avg  weighted avg  \n",
       "precision        1.0           1.0  \n",
       "recall           1.0           1.0  \n",
       "f1-score         1.0           1.0  \n",
       "support         10.0          10.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "device = 'cpu'\n",
    "preds, gts = [], []\n",
    "\n",
    "net = net.to(device)\n",
    "net = net.eval()\n",
    "\n",
    "for x, y in tqdm(test_loader, desc=\"Evaluating model\"):\n",
    "    x = x.to(device)\n",
    "    x = net.preprocess(x)\n",
    "    y = y.to(device)\n",
    "    y_hat = torch.argmax(torch.softmax(net(x), dim=1), dim=1)\n",
    "    preds.append(y_hat.cpu())\n",
    "    gts.append(y.cpu())\n",
    "    print(\"pred: \", LabelEnum(y_hat.item()).name, LabelEnum(y.item()).name)\n",
    "\n",
    "\n",
    "preds_np = np.array(torch.concat(preds).view(-1))\n",
    "gts_np   = np.array(torch.concat(gts).view(-1))\n",
    "\n",
    "report = classification_report(gts_np, preds_np, target_names=[LabelEnum(i).name for i in range(len(LabelEnum))], output_dict=True)\n",
    "pd.DataFrame.from_dict(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_db.image_files[7]\n",
    "im_l, y_l = test_db[7]\n",
    "\n",
    "totens = ToTensor()\n",
    "paf = \"./correction/fix/Apple_Black_rot/Apple_Black_rot1.jpg\"\n",
    "im = totens(Image.open(paf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple_Black_rot\n",
      "tensor([[ 4.3443,  0.5088,  0.2857,  0.3990, -2.0597,  1.4670, -1.6564, -1.1900]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joep/Code/Leafliction/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# x = im.unsqueeze(0)\n",
    "x = im_l.unsqueeze(0)\n",
    "x = x.to(device)\n",
    "x = net.preprocess(x)\n",
    "y_hat = torch.argmax(torch.softmax(net(x), dim=1), dim=1)\n",
    "preds.append(y_hat.cpu())\n",
    "print(LabelEnum(y_hat.item()).name)\n",
    "print(net(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
