{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiated loader on folder /home/joep/Code/Leafliction/images. Found 7233 images.\n",
      "im.shape = torch.Size([3, 256, 256])\n",
      "y.shape = torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from leafy.loader import ImageLoader\n",
    "from leafy.trainloader import ImageDataset\n",
    "\n",
    "data_folder = Path(\"./images\")\n",
    "loader = ImageLoader(data_folder=data_folder)\n",
    "image_db = ImageDataset(loader)\n",
    "train_set, test_set = random_split(image_db, [0.8, 0.2])\n",
    "\n",
    "# class_distribution = loader.get_better_class_distribution()\n",
    "im, y = image_db[0]\n",
    "num_classes = len(y)\n",
    "print(f\"{im.shape = }\\n{y.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from icecream import ic\n",
    "from torch.nn import Module\n",
    "\n",
    "class BasicClassifier(Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BasicClassifier, self).__init__()\n",
    "        resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        modules = list(resnet.children())[:-1]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.fc = nn.Linear(2048, 8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.fc(x.view(x.size(0), -1))\n",
    "        return x\n",
    "        # return F.softmax(x, dim=1) # will break for unbatched data\n",
    "\n",
    "\n",
    "net = BasicClassifier(num_classes = 8)\n",
    "net = net.cuda()\n",
    "\n",
    "\n",
    "preprocess = ResNet50_Weights.DEFAULT.transforms()\n",
    "# resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.974609375\n",
      "118.0\n"
     ]
    }
   ],
   "source": [
    "def memory_stats():\n",
    "    print(torch.cuda.memory_allocated()/1024**2)\n",
    "    print(torch.cuda.memory_reserved()/1024**2)\n",
    "\n",
    "memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456c45ce74c3445787b1c8e81cfee53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joep/Code/Leafliction/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0766, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.8176, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.3559, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.2820, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7468, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8443, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8587, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4458, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5751, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5814, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1551, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3776, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4369, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4134, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2163, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4991, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1849, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6287, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1355, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2937, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1942, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4287, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2797, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2453, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1884, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2627, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3174, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0685, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1552, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1817, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1597, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2898, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4136, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1634, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2981, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0757, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0895, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5570, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0516, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1666, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2424, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1672, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1800, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2581, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2532, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5329, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2852, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2157, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1522, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1862, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1243, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1569, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0713, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1408, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1082, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1286, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3517, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2536, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0759, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1026, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0724, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3087, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1251, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2466, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2672, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2997, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1726, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1002, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5537, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0634, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1664, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2351, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0980, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2946, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0986, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3403, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0699, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2749, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1608, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2736, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0743, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0810, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0877, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0625, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0443, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1465, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1452, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0340, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0798, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0482, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0347, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1397, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0700, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1754, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0812, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2244, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0649, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3427, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0997, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1554, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0574, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0944, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0988, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0557, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0444, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0314, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0528, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0331, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0713, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0197, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3146, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1642, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2393, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1409, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0510, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0618, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0909, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1825, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0747, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0690, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1651, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3098, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1327, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0609, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2328, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2364, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0984, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3998, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1260, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2283, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1746, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0554, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0284, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2410, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1481, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0643, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0728, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4047, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0604, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0909, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7232, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0526, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.1255, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0999, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0942, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0890, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.0500, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.2567, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3375, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam\n",
    "\n",
    "train_loader = DataLoader(train_set, 32, shuffle = True)\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "optim = Adam(net.parameters())\n",
    "\n",
    "for epoch in range(1):\n",
    "    for x, y in tqdm(train_loader):\n",
    "        optim.zero_grad()\n",
    "        x = x.cuda()\n",
    "        x = preprocess(x)\n",
    "        y = y.cuda()\n",
    "        y_hat = net(x)\n",
    "        loss = ce_loss(y_hat, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(loss)\n",
    "\n",
    "optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51f04356d1444d080381da83f9126b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# net = net.eval()\n",
    "test_loader = DataLoader(test_set, 32, shuffle = True)\n",
    "\n",
    "gts = []\n",
    "preds = []\n",
    "\n",
    "for x, y in tqdm(test_loader):\n",
    "    gts.append(torch.argmax(y, dim=1))\n",
    "    y_hat = net(preprocess(x.cuda()))\n",
    "    preds.append(torch.argmax(y_hat, dim=1))\n",
    "\n",
    "# y_hat = F.softmax(net(preprocess(x)))\n",
    "# print(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "getes  = torch.concat(gts)\n",
    "predes = torch.concat(preds).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9620)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(getes == predes).to(torch.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 4,  ..., 6, 7, 0], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
